支付欺诈检测项目（Fraudulent Transactions Data）

一、项目背景
本项目基于大规模支付交易数据，目标是在极度样本不平衡的情况下识别潜在欺诈行为。为了在大数据环境下保持建模效率和可扩展性，整体采用 PySpark 实现，构建了从数据清洗、特征工程到模
型训练、阈值选择与评估的完整流程，应用场景面向金融支付的实时风控系统。

二、数据处理与特征构建
数据清洗阶段主要完成缺失值、重复值与异常值的处理，对金额类字段进行逻辑一致性校验，并删除无信息或常数型变量。
在特征工程阶段，提取账户名称首字符形成账户类型特征，构造账户交叉变量（如 nameOrig 与 nameDest 的组合），生成交易金额差额、余额变动、金额为零的指示变量等。针对时间步字段
step，进行了分布与趋势分析，为后续的时序建模打下基础。

三、模型训练与调优
模型采用 Spark MLlib 的梯度提升树（GBTClassifier），通过随机搜索和交叉验证优化 maxDepth、maxIter、stepSize 等核心参数。针对欺诈样本稀少的问题，引入类别权重与自定义阈值调整方
法以提升召回率。训练过程中使用 Spark Pipeline 结构管理特征转换与建模流程，并将最终模型以 PipelineModel 形式持久化，方便后续加载和部署。

四、模型评估与结果
在验证集上使用自编的 hold_out_threshold 函数自动选择最优阈值，以 Precision-Recall 曲线为主评估标准，重点平衡模型的精确率和召回率。最终模型在测试集上的主要指标为：Precision 约
0.80，Recall 约 0.93，F1-score 约 0.86，ROC-AUC 约 0.995，PR-AUC 约 0.951。模型在保持高召回率的同时控制了误报率，能够有效识别潜在的欺诈交易，表现出良好的业务可用性。

五、项目成果
本项目实现了一个完整的 PySpark 数据建模与评估框架，形成可复用的特征工程与阈值优化模块，支持在分布式环境下进行大规模数据训练与批量预测。模型结果可直接用于风险监控或交易审核流
程，为金融类风控场景提供技术支持。


环境配置
建议使用 Python 3.10。
在项目根目录下运行以下命令以安装依赖：

pip install -r requirements.txt